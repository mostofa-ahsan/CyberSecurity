{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gcamfer/Anomaly-ReactionRL/blob/master/Notebooks/AE_RL_NSL_KDD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e091v728lBCx"
   },
   "source": [
    "# AE-RL for NSL-KDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FEFO4mGvbnlF",
    "outputId": "e0e64e06-ea4b-4ebf-826c-c2d3b482c536"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "import json\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Activation, Dense, Flatten, BatchNormalization, Conv2D, MaxPool2D\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "# from tensorflow.python.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YKA8QTFrb1ZR"
   },
   "outputs": [],
   "source": [
    "class data_cls:\n",
    "    def __init__(self,train_test,**kwargs):\n",
    "        col_names = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "            \"dst_bytes\",\"land_f\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "            \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "            \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "            \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "            \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "            \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "            \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "            \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "            \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"labels\",\"dificulty\"]\n",
    "        self.index = 0\n",
    "        # Data formated path and test path. \n",
    "        self.loaded = False\n",
    "        self.train_test = train_test\n",
    "        self.train_path = kwargs.get('train_path', 'datasets/NSL/KDDTrain+.txt')\n",
    "        self.test_path = kwargs.get('test_path',\n",
    "                                    'https://raw.githubusercontent.com/gcamfer/Anomaly-ReactionRL/master/datasets/NSL/KDDTest%2B.txt')\n",
    "        \n",
    "        self.formated_train_path = kwargs.get('formated_train_path', \n",
    "                                              \"formated_train_adv.data\")\n",
    "        self.formated_test_path = kwargs.get('formated_test_path',\n",
    "                                             \"formated_test_adv.data\")\n",
    "        \n",
    "        self.attack_types = ['normal','DoS','Probe','R2L','U2R']\n",
    "        self.attack_names = []\n",
    "        self.attack_map =   { 'normal': 'normal',\n",
    "                        \n",
    "                        'back': 'DoS',\n",
    "                        'land': 'DoS',\n",
    "                        'neptune': 'DoS',\n",
    "                        'pod': 'DoS',\n",
    "                        'smurf': 'DoS',\n",
    "                        'teardrop': 'DoS',\n",
    "                        'mailbomb': 'DoS',\n",
    "                        'apache2': 'DoS',\n",
    "                        'processtable': 'DoS',\n",
    "                        'udpstorm': 'DoS',\n",
    "                        \n",
    "                        'ipsweep': 'Probe',\n",
    "                        'nmap': 'Probe',\n",
    "                        'portsweep': 'Probe',\n",
    "                        'satan': 'Probe',\n",
    "                        'mscan': 'Probe',\n",
    "                        'saint': 'Probe',\n",
    "                    \n",
    "                        'ftp_write': 'R2L',\n",
    "                        'guess_passwd': 'R2L',\n",
    "                        'imap': 'R2L',\n",
    "                        'multihop': 'R2L',\n",
    "                        'phf': 'R2L',\n",
    "                        'spy': 'R2L',\n",
    "                        'warezclient': 'R2L',\n",
    "                        'warezmaster': 'R2L',\n",
    "                        'sendmail': 'R2L',\n",
    "                        'named': 'R2L',\n",
    "                        'snmpgetattack': 'R2L',\n",
    "                        'snmpguess': 'R2L',\n",
    "                        'xlock': 'R2L',\n",
    "                        'xsnoop': 'R2L',\n",
    "                        'worm': 'R2L',\n",
    "                        \n",
    "                        'buffer_overflow': 'U2R',\n",
    "                        'loadmodule': 'U2R',\n",
    "                        'perl': 'U2R',\n",
    "                        'rootkit': 'U2R',\n",
    "                        'httptunnel': 'U2R',\n",
    "                        'ps': 'U2R',    \n",
    "                        'sqlattack': 'U2R',\n",
    "                        'xterm': 'U2R'\n",
    "                    }\n",
    "        self.all_attack_names = list(self.attack_map.keys())\n",
    "\n",
    "        formated = False     \n",
    "        \n",
    "        # Test formated data exists\n",
    "        if os.path.exists(self.formated_train_path) and os.path.exists(self.formated_test_path):\n",
    "            formated = True\n",
    "       \n",
    "        self.formated_dir = \"../datasets/formated/\"\n",
    "        if not os.path.exists(self.formated_dir):\n",
    "            os.makedirs(self.formated_dir)\n",
    "               \n",
    "            \n",
    "        # If it does not exist, it's needed to format the data\n",
    "        if not formated:\n",
    "            ''' Formating the dataset for ready-2-use data'''\n",
    "            self.df = pd.read_csv(self.train_path,sep=',',names=col_names,index_col=False)\n",
    "            if 'dificulty' in self.df.columns:\n",
    "                self.df.drop('dificulty', axis=1, inplace=True) #in case of difficulty     \n",
    "                \n",
    "            data2 = pd.read_csv(self.test_path,sep=',',names=col_names,index_col=False)\n",
    "            if 'dificulty' in data2:\n",
    "                del(data2['dificulty'])\n",
    "            train_indx = self.df.shape[0]\n",
    "            frames = [self.df,data2]\n",
    "            self.df = pd.concat(frames)\n",
    "            \n",
    "            # Dataframe processing\n",
    "            self.df = pd.concat([self.df.drop('protocol_type', axis=1), pd.get_dummies(self.df['protocol_type'])], axis=1)\n",
    "            self.df = pd.concat([self.df.drop('service', axis=1), pd.get_dummies(self.df['service'])], axis=1)\n",
    "            self.df = pd.concat([self.df.drop('flag', axis=1), pd.get_dummies(self.df['flag'])], axis=1)\n",
    "              \n",
    "            # 1 if ``su root'' command attempted; 0 otherwise \n",
    "            self.df['su_attempted'] = self.df['su_attempted'].replace(2.0, 0.0)\n",
    "            \n",
    "             # One hot encoding for labels\n",
    "            self.df = pd.concat([self.df.drop('labels', axis=1),\n",
    "                            pd.get_dummies(self.df['labels'])], axis=1)\n",
    "            \n",
    "            \n",
    "            # Normalization of the df\n",
    "            #normalized_df=(df-df.mean())/df.std()\n",
    "            for indx,dtype in self.df.dtypes.iteritems():\n",
    "                if dtype == 'float64' or dtype == 'int64':\n",
    "                    if self.df[indx].max() == 0 and self.df[indx].min()== 0:\n",
    "                        self.df[indx] = 0\n",
    "                    else:\n",
    "                        self.df[indx] = (self.df[indx]-self.df[indx].min())/(self.df[indx].max()-self.df[indx].min())\n",
    "            \n",
    "            \n",
    "            # Save data\n",
    "            test_df = self.df.iloc[train_indx:self.df.shape[0]]\n",
    "            test_df = shuffle(test_df,random_state=np.random.randint(0,100))\n",
    "            self.df = self.df[:train_indx]\n",
    "            self.df = shuffle(self.df,random_state=np.random.randint(0,100))\n",
    "            test_df.to_csv(self.formated_test_path,sep=',',index=False)\n",
    "            self.df.to_csv(self.formated_train_path,sep=',',index=False)\n",
    "            \n",
    "            # Create a list with the existent attacks in the df\n",
    "            for att in self.attack_map:\n",
    "                if att in self.df.columns:\n",
    "                # Add only if there is exist at least 1\n",
    "                    if np.sum(self.df[att].values) > 1:\n",
    "                        self.attack_names.append(att)\n",
    "\n",
    "    def get_shape(self):\n",
    "        if self.loaded is False:\n",
    "            self._load_df()\n",
    "        \n",
    "        self.data_shape = self.df.shape\n",
    "        # stata + labels\n",
    "        return self.data_shape\n",
    "    \n",
    "    ''' Get n-rows from loaded data \n",
    "        The dataset must be loaded in RAM\n",
    "    '''\n",
    "    def get_batch(self,batch_size=100):\n",
    "        if self.loaded is False:\n",
    "            self._load_df()\n",
    "        \n",
    "        # Read the df rows\n",
    "        indexes = list(range(self.index,self.index+batch_size))    \n",
    "        if max(indexes)>self.data_shape[0]-1:\n",
    "            dif = max(indexes)-self.data_shape[0]\n",
    "            indexes[len(indexes)-dif-1:len(indexes)] = list(range(dif+1))\n",
    "            self.index=batch_size-dif\n",
    "            batch = self.df.iloc[indexes]\n",
    "        else: \n",
    "            batch = self.df.iloc[indexes]\n",
    "            self.index += batch_size    \n",
    "            \n",
    "        labels = batch[self.attack_names]\n",
    "        \n",
    "        batch = batch.drop(self.all_attack_names,axis=1)\n",
    "            \n",
    "        return batch,labels\n",
    "    \n",
    "    def get_full(self):\n",
    "        if self.loaded is False:\n",
    "            self._load_df()\n",
    "            \n",
    "        \n",
    "        labels = self.df[self.attack_names]\n",
    "        \n",
    "        batch = self.df.drop(self.all_attack_names,axis=1)\n",
    "        \n",
    "\n",
    "        return batch,labels\n",
    "      \n",
    "    def _load_df(self):\n",
    "        if self.train_test == 'train':\n",
    "            self.df = pd.read_csv(self.formated_train_path,sep=',') # Read again the csv\n",
    "        else:\n",
    "            self.df = pd.read_csv(self.formated_test_path,sep=',')\n",
    "        self.index=np.random.randint(0,self.df.shape[0]-1,dtype=np.int32)\n",
    "        self.loaded = True\n",
    "         # Create a list with the existent attacks in the df\n",
    "        for att in self.attack_map:\n",
    "            if att in self.df.columns:\n",
    "                # Add only if there is exist at least 1\n",
    "                if np.sum(self.df[att].values) > 1:\n",
    "                    self.attack_names.append(att)\n",
    "        #self.headers = list(self.df)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DbMxSATehU-"
   },
   "outputs": [],
   "source": [
    "# Huber loss function        \n",
    "def huber_loss(y_true, y_pred, clip_value=1):\n",
    "    # Huber loss, see https://en.wikipedia.org/wiki/Huber_loss and\n",
    "    # https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b\n",
    "    # for details.\n",
    "    assert clip_value > 0.\n",
    "\n",
    "    x = y_true - y_pred\n",
    "    if np.isinf(clip_value):\n",
    "        # Spacial case for infinity since Tensorflow does have problems\n",
    "        # if we compare `K.abs(x) < np.inf`.\n",
    "        return .5 * K.square(x)\n",
    "\n",
    "    condition = K.abs(x) < clip_value\n",
    "    squared_loss = .5 * K.square(x)\n",
    "    linear_loss = clip_value * (K.abs(x) - .5 * clip_value)\n",
    "    if K.backend() == 'tensorflow':\n",
    "        import tensorflow as tf\n",
    "        if hasattr(tf, 'select'):\n",
    "            return tf.select(condition, squared_loss, linear_loss)  # condition, true, false\n",
    "        else:\n",
    "            return tf.where(condition, squared_loss, linear_loss)  # condition, true, false\n",
    "    elif K.backend() == 'theano':\n",
    "        from theano import tensor as T\n",
    "        return T.switch(condition, squared_loss, linear_loss)\n",
    "    else:\n",
    "        raise RuntimeError('Unknown backend \"{}\".'.format(K.backend()))\n",
    "\n",
    "# Needed for keras huber_loss locate\n",
    "import keras.losses\n",
    "keras.losses.huber_loss = huber_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7XkKb6WaesLN"
   },
   "outputs": [],
   "source": [
    "class QNetwork():\n",
    "    \"\"\"\n",
    "    Q-Network Estimator\n",
    "    Represents the global model for the table\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,obs_size,num_actions,hidden_size = 100,\n",
    "                 hidden_layers = 1,learning_rate=.2):\n",
    "        \"\"\"\n",
    "        Initialize the network with the provided shape\n",
    "        \"\"\"\n",
    "        self.obs_size = obs_size\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        # Network arquitecture\n",
    "        self.model = Sequential()\n",
    "        # Add imput layer\n",
    "        self.model.add(Dense(hidden_size, input_shape=(obs_size,),\n",
    "                             activation='relu'))\n",
    "        # Add hidden layers\n",
    "        for layers in range(hidden_layers):\n",
    "            self.model.add(Dense(hidden_size, activation='relu'))\n",
    "        # Add output layer    \n",
    "        self.model.add(Dense(num_actions))\n",
    "        \n",
    "        #optimizer = optimizers.SGD(learning_rate)\n",
    "        # optimizer = optimizers.Adam(alpha=learning_rate)\n",
    "#         optimizer = tensorflow.keras.optimizers.Adam(0.00025)\n",
    "        optimizer = Adam(0.00025)\n",
    "        # optimizer = optimizers.RMSpropGraves(learning_rate, 0.95, self.momentum, 1e-2)\n",
    "        \n",
    "        # Compilation of the model with optimizer and loss\n",
    "        self.model.compile(loss=huber_loss,optimizer=optimizer)\n",
    "\n",
    "    def predict(self,state,batch_size=1):\n",
    "        \"\"\"\n",
    "        Predicts action values.\n",
    "        \"\"\"\n",
    "        return self.model.predict(state,batch_size=batch_size)\n",
    "\n",
    "    def update(self, states, q):\n",
    "        \"\"\"\n",
    "        Updates the estimator with the targets.\n",
    "\n",
    "        Args:\n",
    "          states: Target states\n",
    "          q: Estimated values\n",
    "\n",
    "        Returns:\n",
    "          The calculated loss on the batch.\n",
    "        \"\"\"\n",
    "        loss = self.model.train_on_batch(states, q)\n",
    "        return loss\n",
    "    \n",
    "    def copy_model(model):\n",
    "        \"\"\"Returns a copy of a keras model.\"\"\"\n",
    "        model.save('tmp_model')\n",
    "        return keras.models.load_model('tmp_model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-u8-r77Jexf2"
   },
   "outputs": [],
   "source": [
    "#Policy interface\n",
    "class Policy:\n",
    "    def __init__(self, num_actions, estimator):\n",
    "        self.num_actions = num_actions\n",
    "        self.estimator = estimator\n",
    "    \n",
    "class Epsilon_greedy(Policy):\n",
    "    def __init__(self,estimator ,num_actions ,epsilon,min_epsilon,decay_rate, epoch_length):\n",
    "        Policy.__init__(self, num_actions, estimator)\n",
    "        self.name = \"Epsilon Greedy\"\n",
    "        \n",
    "        if (epsilon is None or epsilon < 0 or epsilon > 1):\n",
    "            print(\"EpsilonGreedy: Invalid value of epsilon\", flush = True)\n",
    "            sys.exit(0)\n",
    "        self.epsilon = epsilon\n",
    "        self.min_epsilon = min_epsilon\n",
    "        self.actions = list(range(num_actions))\n",
    "        self.step_counter = 0\n",
    "        self.epoch_length = epoch_length\n",
    "        self.decay_rate = decay_rate\n",
    "        \n",
    "        #if epsilon is up 0.1, it will be decayed over time\n",
    "        if self.epsilon > 0.01:\n",
    "            self.epsilon_decay = True\n",
    "        else:\n",
    "            self.epsilon_decay = False\n",
    "    \n",
    "    def get_actions(self,states):\n",
    "        # get next action\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            actions = np.random.randint(0, self.num_actions,states.shape[0])\n",
    "        else:\n",
    "            self.Q = self.estimator.predict(states,states.shape[0])\n",
    "            actions = []\n",
    "            for row in range(self.Q.shape[0]):\n",
    "                best_actions = np.argwhere(self.Q[row] == np.amax(self.Q[row]))\n",
    "                actions.append(best_actions[np.random.choice(len(best_actions))].item())\n",
    "            \n",
    "        self.step_counter += 1 \n",
    "        # decay epsilon after each epoch\n",
    "        if self.epsilon_decay:\n",
    "            if self.step_counter % self.epoch_length == 0:\n",
    "                self.epsilon = max(self.min_epsilon, self.epsilon * self.decay_rate**self.step_counter)\n",
    "            \n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2gBTfI8ke08v"
   },
   "outputs": [],
   "source": [
    "class ReplayMemory(object):\n",
    "    \"\"\"Implements basic replay memory\"\"\"\n",
    "\n",
    "    def __init__(self, observation_size, max_size):\n",
    "        self.observation_size = observation_size\n",
    "        self.num_observed = 0\n",
    "        self.max_size = max_size\n",
    "        self.samples = {\n",
    "                 'obs'      : np.zeros(self.max_size * 1 * self.observation_size,\n",
    "                                       dtype=np.float32).reshape(self.max_size,self.observation_size),\n",
    "                 'action'   : np.zeros(self.max_size * 1, dtype=np.int16).reshape(self.max_size, 1),\n",
    "                 'reward'   : np.zeros(self.max_size * 1).reshape(self.max_size, 1),\n",
    "                 'terminal' : np.zeros(self.max_size * 1, dtype=np.int16).reshape(self.max_size, 1),\n",
    "               }\n",
    "\n",
    "    def observe(self, state, action, reward, done):\n",
    "        index = self.num_observed % self.max_size\n",
    "        self.samples['obs'][index, :] = state\n",
    "        self.samples['action'][index, :] = action\n",
    "        self.samples['reward'][index, :] = reward\n",
    "        self.samples['terminal'][index, :] = done\n",
    "\n",
    "        self.num_observed += 1\n",
    "\n",
    "    def sample_minibatch(self, minibatch_size):\n",
    "        max_index = min(self.num_observed, self.max_size) - 1\n",
    "        sampled_indices = np.random.randint(max_index, size=minibatch_size)\n",
    "\n",
    "        s      = np.asarray(self.samples['obs'][sampled_indices, :], dtype=np.float32)\n",
    "        s_next = np.asarray(self.samples['obs'][sampled_indices+1, :], dtype=np.float32)\n",
    "\n",
    "        a      = self.samples['action'][sampled_indices].reshape(minibatch_size)\n",
    "        r      = self.samples['reward'][sampled_indices].reshape((minibatch_size, 1))\n",
    "        done   = self.samples['terminal'][sampled_indices].reshape((minibatch_size, 1))\n",
    "\n",
    "        return (s, a, r, s_next, done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qXeEzOaIe32m"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Reinforcement learning Agent definition\n",
    "'''\n",
    "\n",
    "class Agent(object):  \n",
    "        \n",
    "    def __init__(self, actions,obs_size, policy=\"EpsilonGreedy\", **kwargs):\n",
    "        self.actions = actions\n",
    "        self.num_actions = len(actions)\n",
    "        self.obs_size = obs_size\n",
    "        \n",
    "        self.epsilon = kwargs.get('epsilon', 1)\n",
    "        self.min_epsilon = kwargs.get('min_epsilon', .1)\n",
    "        self.gamma = kwargs.get('gamma', .001)\n",
    "        self.minibatch_size = kwargs.get('minibatch_size', 2)\n",
    "        self.epoch_length = kwargs.get('epoch_length', 100)\n",
    "        self.decay_rate = kwargs.get('decay_rate',0.99)\n",
    "        self.ExpRep = kwargs.get('ExpRep',True)\n",
    "        if self.ExpRep:\n",
    "            self.memory = ReplayMemory(self.obs_size, kwargs.get('mem_size', 10))\n",
    "        \n",
    "        self.ddqn_time = 100\n",
    "        self.ddqn_update = self.ddqn_time\n",
    "\n",
    "        \n",
    "        self.model_network = QNetwork(self.obs_size, self.num_actions,\n",
    "                                      kwargs.get('hidden_size', 100),\n",
    "                                      kwargs.get('hidden_layers',1),\n",
    "                                      kwargs.get('learning_rate',.2))\n",
    "        self.target_model_network = QNetwork(self.obs_size, self.num_actions,\n",
    "                                      kwargs.get('hidden_size', 100),\n",
    "                                      kwargs.get('hidden_layers',1),\n",
    "                                      kwargs.get('learning_rate',.2))\n",
    "        self.target_model_network.model = QNetwork.copy_model(self.model_network.model)\n",
    "        \n",
    "        if policy == \"EpsilonGreedy\":\n",
    "            self.policy = Epsilon_greedy(self.model_network,len(actions),\n",
    "                                         self.epsilon,self.min_epsilon,\n",
    "                                         self.decay_rate,self.epoch_length)\n",
    "        \n",
    "        \n",
    "    def learn(self, states, actions,next_states, rewards, done):\n",
    "        if self.ExpRep:\n",
    "            self.memory.observe(states, actions, rewards, done)\n",
    "        else:\n",
    "            self.states = states\n",
    "            self.actions = actions\n",
    "            self.next_states = next_states\n",
    "            self.rewards = rewards\n",
    "            self.done = done        \n",
    "    def update_model(self):\n",
    "        if self.ExpRep:\n",
    "            (states, actions, rewards, next_states, done) = self.memory.sample_minibatch(self.minibatch_size)\n",
    "        else:\n",
    "            states = self.states\n",
    "            rewards = self.rewards\n",
    "            next_states = self.next_states\n",
    "            actions = self.actions\n",
    "            done = self.done\n",
    "        \n",
    "        next_actions = []\n",
    "        # Compute Q targets\n",
    "#        Q_prime = self.model_network.predict(next_states,self.minibatch_size)\n",
    "        Q_prime = self.target_model_network.predict(next_states,self.minibatch_size)\n",
    "        # TODO: fix performance in this loop\n",
    "        for row in range(Q_prime.shape[0]):\n",
    "            best_next_actions = np.argwhere(Q_prime[row] == np.amax(Q_prime[row]))\n",
    "            next_actions.append(best_next_actions[np.random.choice(len(best_next_actions))].item())\n",
    "        sx = np.arange(len(next_actions))\n",
    "        # Compute Q(s,a)\n",
    "        Q = self.model_network.predict(states,self.minibatch_size)\n",
    "        # Q-learning update\n",
    "        # target = reward + gamma * max_a'{Q(next_state,next_action))}\n",
    "        targets = rewards.reshape(Q[sx,actions].shape) + \\\n",
    "                  self.gamma * Q[sx,next_actions] * \\\n",
    "                  (1-done.reshape(Q[sx,actions].shape))   \n",
    "        Q[sx,actions] = targets  \n",
    "        \n",
    "        loss = self.model_network.model.train_on_batch(states,Q)#inputs,targets        \n",
    "        \n",
    "        # timer to ddqn update\n",
    "        self.ddqn_update -= 1\n",
    "        if self.ddqn_update == 0:\n",
    "            self.ddqn_update = self.ddqn_time\n",
    "#            self.target_model_network.model = QNetwork.copy_model(self.model_network.model)\n",
    "            self.target_model_network.model.set_weights(self.model_network.model.get_weights()) \n",
    "        \n",
    "        return loss    \n",
    "\n",
    "    def act(self, state,policy):\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yzoWE1L8fCKP"
   },
   "outputs": [],
   "source": [
    "class DefenderAgent(Agent):      \n",
    "    def __init__(self, actions, obs_size, policy=\"EpsilonGreedy\", **kwargs):\n",
    "        super().__init__(actions,obs_size, policy=\"EpsilonGreedy\", **kwargs)\n",
    "        \n",
    "    def act(self,states):\n",
    "        # Get actions under the policy\n",
    "        actions = self.policy.get_actions(states)\n",
    "        return actions\n",
    "    \n",
    "class AttackAgent(Agent):      \n",
    "    def __init__(self, actions, obs_size, policy=\"EpsilonGreedy\", **kwargs):\n",
    "        super().__init__(actions,obs_size, policy=\"EpsilonGreedy\", **kwargs)\n",
    "        \n",
    "    def act(self,states):\n",
    "        # Get actions under the policy\n",
    "        actions = self.policy.get_actions(states)\n",
    "        return actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ojLCmmE3fCpw"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Reinforcement learning Enviroment Definition\n",
    "'''\n",
    "class RLenv(data_cls):\n",
    "    def __init__(self,train_test,**kwargs):\n",
    "        data_cls.__init__(self,train_test,**kwargs)\n",
    "        data_cls._load_df(self)\n",
    "        self.data_shape = data_cls.get_shape(self)\n",
    "        self.batch_size = kwargs.get('batch_size',1) # experience replay -> batch = 1\n",
    "        self.iterations_episode = kwargs.get('iterations_episode',10)\n",
    "        if self.batch_size=='full':\n",
    "            self.batch_size = int(self.data_shape[0]/iterations_episode)\n",
    "\n",
    "\n",
    "    '''\n",
    "    _update_state: function to update the current state\n",
    "    Returns:\n",
    "        None\n",
    "    Modifies the self parameters involved in the state:\n",
    "        self.state and self.labels\n",
    "    Also modifies the true labels to get learning knowledge\n",
    "    '''\n",
    "    def _update_state(self):        \n",
    "        self.states,self.labels = data_cls.get_batch(self)\n",
    "        \n",
    "        # Update statistics\n",
    "        self.true_labels += np.sum(self.labels).values\n",
    "\n",
    "    '''\n",
    "    Returns:\n",
    "        + Observation of the enviroment\n",
    "    '''\n",
    "    def reset(self):\n",
    "        # Statistics\n",
    "        self.def_true_labels = np.zeros(len(self.attack_types),dtype=int)\n",
    "        self.def_estimated_labels = np.zeros(len(self.attack_types),dtype=int)\n",
    "        self.att_true_labels = np.zeros(len(self.attack_names),dtype=int)\n",
    "        \n",
    "        self.state_numb = 0\n",
    "        \n",
    "        data_cls._load_df(self) # Reload and random index\n",
    "        self.states,self.labels = data_cls.get_batch(self,self.batch_size)\n",
    "        \n",
    "        self.total_reward = 0\n",
    "        self.steps_in_episode = 0\n",
    "        return self.states.values \n",
    "   \n",
    "    '''\n",
    "    Returns:\n",
    "        State: Next state for the game\n",
    "        Reward: Actual reward\n",
    "        done: If the game ends (no end in this case)\n",
    "    \n",
    "    In the adversarial enviroment, it's only needed to return the actual reward\n",
    "    '''    \n",
    "    def act(self,defender_actions,attack_actions):\n",
    "        # Clear previous rewards        \n",
    "        self.att_reward = np.zeros(len(attack_actions))       \n",
    "        self.def_reward = np.zeros(len(defender_actions))\n",
    "        \n",
    "        \n",
    "        attack = [self.attack_types.index(self.attack_map[self.attack_names[att]]) for att in attack_actions]\n",
    "        \n",
    "        self.def_reward = (np.asarray(defender_actions)==np.asarray(attack))*1\n",
    "        self.att_reward = (np.asarray(defender_actions)!=np.asarray(attack))*1\n",
    "\n",
    "         \n",
    "       \n",
    "        self.def_estimated_labels += np.bincount(defender_actions,minlength=len(self.attack_types))\n",
    "        # TODO\n",
    "        # list comprehension\n",
    "        \n",
    "        for act in attack_actions:\n",
    "            self.def_true_labels[self.attack_types.index(self.attack_map[self.attack_names[act]])] += 1\n",
    "        \n",
    "\n",
    "        # Get new state and new true values \n",
    "        attack_actions = attacker_agent.act(self.states)\n",
    "        self.states = env.get_states(attack_actions)\n",
    "        \n",
    "        # Done allways false in this continuous task       \n",
    "        self.done = np.zeros(len(attack_actions),dtype=bool)\n",
    "            \n",
    "        return self.states, self.def_reward,self.att_reward, attack_actions, self.done\n",
    "    \n",
    "    '''\n",
    "    Provide the actual states for the selected attacker actions\n",
    "    Parameters:\n",
    "        self:\n",
    "        attacker_actions: optimum attacks selected by the attacker\n",
    "            it can be one of attack_names list and select random of this\n",
    "    Returns:\n",
    "        State: Actual state for the selected attacks\n",
    "    '''\n",
    "    def get_states(self,attacker_actions):\n",
    "        first = True\n",
    "        for attack in attacker_actions:\n",
    "            if first:\n",
    "                minibatch = (self.df[self.df[self.attack_names[attack]]==1].sample(1))\n",
    "                first = False\n",
    "            else:\n",
    "                minibatch=minibatch.append(self.df[self.df[self.attack_names[attack]]==1].sample(1))\n",
    "        \n",
    "        self.labels = minibatch[self.attack_names]\n",
    "        minibatch.drop(self.all_attack_names,axis=1,inplace=True)\n",
    "        self.states = minibatch\n",
    "        \n",
    "        return self.states\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8568
    },
    "colab_type": "code",
    "id": "M0eU7ZSGfNEB",
    "outputId": "580bd4d2-c5c2-4789-fb1f-95aa23819ce8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: tmp_model\\assets\n",
      "INFO:tensorflow:Assets written to: tmp_model\\assets\n",
      "-------------------------------------------------------------------------------\n",
      "Total epoch: 100 | Iterations in epoch: 100| Minibatch from mem size: 100 | Total Samples: 10000|\n",
      "-------------------------------------------------------------------------------\n",
      "Dataset shape: (125973, 162)\n",
      "-------------------------------------------------------------------------------\n",
      "Attacker parameters: Num_actions=23 | gamma=0.001 | epsilon=1 | ANN hidden size=100 | ANN hidden layers=1|\n",
      "-------------------------------------------------------------------------------\n",
      "Defense parameters: Num_actions=5 | gamma=0.001 | epsilon=1 | ANN hidden size=100 | ANN hidden layers=3|\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "|Epoch 000/100| time: 3.35|\n",
      "|Def Loss 0.0000 | Def Reward in ep 017|\n",
      "|Att Loss 0.0000 | Att Reward in ep 083|\n",
      "|Def Estimated: [23 22 15 23 17]| Att Labels: [ 6 27 14 33 20]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A08E694B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001A0A79A4AF0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "|Epoch 001/100| time: 19.59|\n",
      "|Def Loss 0.8337 | Def Reward in ep 047|\n",
      "|Att Loss 0.7737 | Att Reward in ep 053|\n",
      "|Def Estimated: [ 7 28 11 31 23]| Att Labels: [ 5 22 14 36 23]\n",
      "\n",
      "|Epoch 002/100| time: 19.14|\n",
      "|Def Loss 0.2883 | Def Reward in ep 077|\n",
      "|Att Loss 0.4233 | Att Reward in ep 023|\n",
      "|Def Estimated: [ 2 26 12 42 18]| Att Labels: [ 4 22 19 40 15]\n",
      "\n",
      "|Epoch 003/100| time: 19.57|\n",
      "|Def Loss 0.2703 | Def Reward in ep 074|\n",
      "|Att Loss 0.3986 | Att Reward in ep 026|\n",
      "|Def Estimated: [ 0 31 16 31 22]| Att Labels: [11 24 15 27 23]\n",
      "\n",
      "|Epoch 004/100| time: 19.55|\n",
      "|Def Loss 0.2717 | Def Reward in ep 083|\n",
      "|Att Loss 0.3586 | Att Reward in ep 017|\n",
      "|Def Estimated: [ 1 26 25 35 13]| Att Labels: [ 7 24 19 34 16]\n",
      "\n",
      "|Epoch 005/100| time: 20.25|\n",
      "|Def Loss 0.2423 | Def Reward in ep 087|\n",
      "|Att Loss 0.3447 | Att Reward in ep 013|\n",
      "|Def Estimated: [ 3 26 16 30 25]| Att Labels: [ 6 21 17 25 31]\n",
      "\n",
      "|Epoch 006/100| time: 23.19|\n",
      "|Def Loss 0.2108 | Def Reward in ep 085|\n",
      "|Att Loss 0.3016 | Att Reward in ep 015|\n",
      "|Def Estimated: [ 5 26 17 34 18]| Att Labels: [ 9 22 14 30 25]\n",
      "\n",
      "|Epoch 007/100| time: 23.58|\n",
      "|Def Loss 0.2230 | Def Reward in ep 092|\n",
      "|Att Loss 0.3012 | Att Reward in ep 008|\n",
      "|Def Estimated: [11 25 17 25 22]| Att Labels: [13 26 16 24 21]\n",
      "\n",
      "|Epoch 008/100| time: 23.06|\n",
      "|Def Loss 0.1918 | Def Reward in ep 091|\n",
      "|Att Loss 0.2916 | Att Reward in ep 009|\n",
      "|Def Estimated: [13 17 18 35 17]| Att Labels: [12 19 18 33 18]\n",
      "\n",
      "|Epoch 009/100| time: 23.60|\n",
      "|Def Loss 0.1826 | Def Reward in ep 092|\n",
      "|Att Loss 0.2759 | Att Reward in ep 008|\n",
      "|Def Estimated: [13 15 23 29 20]| Att Labels: [14 17 22 25 22]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7116/1869143916.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    162\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mExpRep\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0miterations_episode\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mi_iteration\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[0mdef_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdefender_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m                 \u001b[0matt_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mattacker_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mExpRep\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m                 \u001b[0mdef_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdefender_agent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7116/3546260995.py\u001b[0m in \u001b[0;36mupdate_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[0msx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnext_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m         \u001b[1;31m# Compute Q(s,a)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m         \u001b[0mQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_network\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminibatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m         \u001b[1;31m# Q-learning update\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[1;31m# target = reward + gamma * max_a'{Q(next_state,next_action))}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7116/3298868515.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, state, batch_size)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[0mPredicts\u001b[0m \u001b[0maction\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m         \"\"\"\n\u001b[1;32m---> 39\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RTX2080\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RTX2080\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1949\u001b[0m               stacklevel=2)\n\u001b[0;32m   1950\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1951\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1952\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1953\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RTX2080\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1397\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1398\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1399\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RTX2080\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1148\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     self._adapter = adapter_cls(\n\u001b[0m\u001b[0;32m   1150\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\RTX2080\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    273\u001b[0m     \u001b[1;31m# 5. disabled static optimizations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"batch\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    277\u001b[0m       \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mrange\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1178\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1179\u001b[0m     \"\"\"\n\u001b[1;32m-> 1180\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mRangeDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1182\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   4705\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4706\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_structure\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtensor_spec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorSpec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4707\u001b[1;33m     variant_tensor = gen_dataset_ops.range_dataset(\n\u001b[0m\u001b[0;32m   4708\u001b[0m         \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4709\u001b[0m         \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py\u001b[0m in \u001b[0;36mrange_dataset\u001b[1;34m(start, stop, step, output_types, output_shapes, metadata, name)\u001b[0m\n\u001b[0;32m   6055\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6056\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6057\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   6058\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"RangeDataset\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"output_types\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6059\u001b[0m         output_types, \"output_shapes\", output_shapes, \"metadata\", metadata)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  \n",
    "    kdd_train = \"https://raw.githubusercontent.com/gcamfer/Anomaly-ReactionRL/master/datasets/NSL/KDDTrain%2B.txt\"\n",
    "    kdd_test = \"https://raw.githubusercontent.com/gcamfer/Anomaly-ReactionRL/master/datasets/NSL/KDDTest%2B.txt\"\n",
    "\n",
    "    formated_train_path = \"formated_train_adv.data\"\n",
    "    formated_test_path = \"formated_test_adv.data\"\n",
    "    \n",
    "    \n",
    "    # Train batch\n",
    "    batch_size = 1\n",
    "    # batch of memory ExpRep\n",
    "    minibatch_size = 100\n",
    "    ExpRep = True\n",
    "    \n",
    "    iterations_episode = 100\n",
    "  \n",
    "    # Initialization of the enviroment\n",
    "    env = RLenv('train',train_path=kdd_train,test_path=kdd_test,\n",
    "                formated_train_path = formated_train_path,\n",
    "                formated_test_path = formated_test_path,batch_size=batch_size,\n",
    "                iterations_episode=iterations_episode)    \n",
    "    # obs_size = size of the state\n",
    "    obs_size = env.data_shape[1]-len(env.all_attack_names)\n",
    "    \n",
    "    #num_episodes = int(env.data_shape[0]/(iterations_episode)/10)\n",
    "    num_episodes = 100\n",
    "    \n",
    "    '''\n",
    "    Definition for the defensor agent.\n",
    "    '''\n",
    "    defender_valid_actions = list(range(len(env.attack_types))) # only detect type of attack\n",
    "    defender_num_actions = len(defender_valid_actions)    \n",
    "    \n",
    "\t\n",
    "    def_epsilon = 1 # exploration\n",
    "    min_epsilon = 0.01 # min value for exploration\n",
    "    def_gamma = 0.001\n",
    "    def_decay_rate = 0.99\n",
    "    \n",
    "    def_hidden_size = 100\n",
    "    def_hidden_layers = 3\n",
    "    \n",
    "    def_learning_rate = .2\n",
    "    \n",
    "    defender_agent = DefenderAgent(defender_valid_actions,obs_size,\"EpsilonGreedy\",\n",
    "                          epoch_length = iterations_episode,\n",
    "                          epsilon = def_epsilon,\n",
    "                          min_epsilon = min_epsilon,\n",
    "                          decay_rate = def_decay_rate,\n",
    "                          gamma = def_gamma,\n",
    "                          hidden_size=def_hidden_size,\n",
    "                          hidden_layers=def_hidden_layers,\n",
    "                          minibatch_size = minibatch_size,\n",
    "                          mem_size = 1000,\n",
    "                          learning_rate=def_learning_rate,\n",
    "                          ExpRep=ExpRep)\n",
    "    #Pretrained defender\n",
    "    #defender_agent.model_network.model.load_weights(\"models/type_model.h5\")    \n",
    "    \n",
    "    '''\n",
    "    Definition for the attacker agent.\n",
    "    In this case the exploration is better to be greater\n",
    "    The correlation sould be greater too so gamma bigger\n",
    "    '''\n",
    "    attack_valid_actions = list(range(len(env.attack_names)))\n",
    "    attack_num_actions = len(attack_valid_actions)\n",
    "\t\n",
    "    att_epsilon = 1\n",
    "    min_epsilon = 0.82 # min value for exploration\n",
    "\n",
    "    att_gamma = 0.001\n",
    "    att_decay_rate = 0.99\n",
    "    \n",
    "    att_hidden_layers = 1\n",
    "    att_hidden_size = 100\n",
    "    \n",
    "    att_learning_rate = 0.2\n",
    "    \n",
    "    attacker_agent = AttackAgent(attack_valid_actions,obs_size,\"EpsilonGreedy\",\n",
    "                          epoch_length = iterations_episode,\n",
    "                          epsilon = att_epsilon,\n",
    "                          min_epsilon = min_epsilon,\n",
    "                          decay_rate = att_decay_rate,\n",
    "                          gamma = att_gamma,\n",
    "                          hidden_size=att_hidden_size,\n",
    "                          hidden_layers=att_hidden_layers,\n",
    "                          minibatch_size = minibatch_size,\n",
    "                          mem_size = 1000,\n",
    "                          learning_rate=att_learning_rate,\n",
    "                          ExpRep=ExpRep)\n",
    "    \n",
    "        \n",
    "    \n",
    "    # Statistics\n",
    "    att_reward_chain = []\n",
    "    def_reward_chain = []\n",
    "    att_loss_chain = []\n",
    "    def_loss_chain = []\n",
    "    def_total_reward_chain = []\n",
    "    att_total_reward_chain = []\n",
    "    \n",
    "\t# Print parameters\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"Total epoch: {} | Iterations in epoch: {}\"\n",
    "          \"| Minibatch from mem size: {} | Total Samples: {}|\".format(num_episodes,\n",
    "                         iterations_episode,minibatch_size,\n",
    "                         num_episodes*iterations_episode))\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"Dataset shape: {}\".format(env.data_shape))\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"Attacker parameters: Num_actions={} | gamma={} |\" \n",
    "          \" epsilon={} | ANN hidden size={} | \"\n",
    "          \"ANN hidden layers={}|\".format(attack_num_actions,\n",
    "                             att_gamma,att_epsilon, att_hidden_size,\n",
    "                             att_hidden_layers))\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "    print(\"Defense parameters: Num_actions={} | gamma={} | \"\n",
    "          \"epsilon={} | ANN hidden size={} |\"\n",
    "          \" ANN hidden layers={}|\".format(defender_num_actions,\n",
    "                              def_gamma,def_epsilon,def_hidden_size,\n",
    "                              def_hidden_layers))\n",
    "    print(\"-------------------------------------------------------------------------------\")\n",
    "\n",
    "    # Main loop\n",
    "    attacks_by_epoch = []\n",
    "    attack_labels_list = []\n",
    "    for epoch in range(num_episodes):\n",
    "        start_time = time.time()\n",
    "        att_loss = 0.\n",
    "        def_loss = 0.\n",
    "        def_total_reward_by_episode = 0\n",
    "        att_total_reward_by_episode = 0\n",
    "        # Reset enviromet, actualize the data batch with random state/attacks\n",
    "        states = env.reset()\n",
    "        \n",
    "        # Get actions for actual states following the policy\n",
    "        attack_actions = attacker_agent.act(states)\n",
    "        states = env.get_states(attack_actions)    \n",
    "        \n",
    "        done = False\n",
    "       \n",
    "        attacks_list = []\n",
    "        # Iteration in one episode\n",
    "        for i_iteration in range(iterations_episode):\n",
    "            \n",
    "            attacks_list.append(attack_actions[0])\n",
    "            # apply actions, get rewards and new state\n",
    "            act_time = time.time()  \n",
    "            defender_actions = defender_agent.act(states)\n",
    "            #Enviroment actuation for this actions\n",
    "            next_states,def_reward, att_reward,next_attack_actions, done = env.act(defender_actions,attack_actions)\n",
    "            # If the epoch*batch_size*iterations_episode is largest than the df\n",
    "\n",
    "            \n",
    "            attacker_agent.learn(states,attack_actions,next_states,att_reward,done)\n",
    "            defender_agent.learn(states,defender_actions,next_states,def_reward,done)\n",
    "            \n",
    "            act_end_time = time.time()\n",
    "            \n",
    "            # Train network, update loss after at least minibatch_learns\n",
    "            if ExpRep and epoch*iterations_episode + i_iteration >= minibatch_size:\n",
    "                def_loss += defender_agent.update_model()\n",
    "                att_loss += attacker_agent.update_model()\n",
    "            elif not ExpRep:\n",
    "                def_loss += defender_agent.update_model()\n",
    "                att_loss += attacker_agent.update_model()\n",
    "                \n",
    "\n",
    "            update_end_time = time.time()\n",
    "\n",
    "            # Update the state\n",
    "            states = next_states\n",
    "            attack_actions = next_attack_actions\n",
    "            \n",
    "            \n",
    "            # Update statistics\n",
    "            def_total_reward_by_episode += np.sum(def_reward,dtype=np.int32)\n",
    "            att_total_reward_by_episode += np.sum(att_reward,dtype=np.int32)\n",
    "        \n",
    "        attacks_by_epoch.append(attacks_list)\n",
    "        # Update user view\n",
    "        def_reward_chain.append(def_total_reward_by_episode) \n",
    "        att_reward_chain.append(att_total_reward_by_episode) \n",
    "        def_loss_chain.append(def_loss)\n",
    "        att_loss_chain.append(att_loss) \n",
    "\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(\"\\r\\n|Epoch {:03d}/{:03d}| time: {:2.2f}|\\r\\n\"\n",
    "                \"|Def Loss {:4.4f} | Def Reward in ep {:03d}|\\r\\n\"\n",
    "                \"|Att Loss {:4.4f} | Att Reward in ep {:03d}|\"\n",
    "                .format(epoch, num_episodes,(end_time-start_time), \n",
    "                def_loss, def_total_reward_by_episode,\n",
    "                att_loss, att_total_reward_by_episode))\n",
    "        \n",
    "        \n",
    "        print(\"|Def Estimated: {}| Att Labels: {}\".format(env.def_estimated_labels,\n",
    "              env.def_true_labels))\n",
    "        attack_labels_list.append(env.def_true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w56BPg3zo0DC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W2QzwrilomWO"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302
    },
    "colab_type": "code",
    "id": "OoBlm8f7fW_C",
    "outputId": "415bce2e-2faa-484f-8eb7-9b43b23bf675"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not os.path.exists('models'):\n",
    "    os.makedirs('models')\n",
    "# Save trained model weights and architecture, used in test\n",
    "defender_agent.model_network.model.save_weights(\"models/defender_agent_model.h5\", overwrite=True)\n",
    "with open(\"models/defender_agent_model.json\", \"w\") as outfile:\n",
    "    json.dump(defender_agent.model_network.model.to_json(), outfile)\n",
    "\n",
    "\n",
    "    \n",
    "if not os.path.exists('results'):\n",
    "    os.makedirs('results')    \n",
    "# Plot training results\n",
    "plt.figure(1)\n",
    "plt.subplot(211)\n",
    "plt.plot(np.arange(len(def_reward_chain)),def_reward_chain,label='Defense')\n",
    "plt.plot(np.arange(len(att_reward_chain)),att_reward_chain,label='Attack')\n",
    "plt.title('Total reward by episode')\n",
    "plt.xlabel('n Episode')\n",
    "plt.ylabel('Total reward')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "       ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "plt.subplot(212)\n",
    "plt.plot(np.arange(len(def_loss_chain)),def_loss_chain,label='Defense')\n",
    "plt.plot(np.arange(len(att_loss_chain)),att_loss_chain,label='Attack')\n",
    "plt.title('Loss by episode')\n",
    "plt.xlabel('n Episode')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "       ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('results/train_adv.eps', format='eps', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1081
    },
    "colab_type": "code",
    "id": "HHpLDW9kfeQL",
    "outputId": "e4a20a64-5f88-4f60-be3d-65aac1e3cd21"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bins' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_7116/456193483.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mindx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattacks_by_epoch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbins\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0malign\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'left'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{} epoch\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#     plt.xticks(bins, env.attack_names, rotation=90)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'bins' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# bins=np.arange(5) -0.5\n",
    "# Plot attacks distribution alongside\n",
    "plt.figure(2,figsize=[12,5])\n",
    "plt.title(\"Attacks distribution throughout  episodes\")\n",
    "for indx,e in enumerate([0,70,90]):\n",
    "    plt.subplot(1,3,indx+1)\n",
    "    plt.hist(attacks_by_epoch[e],bins=bins,width=0.9,align='left')\n",
    "    plt.xlabel(\"{} epoch\".format(e))\n",
    "#     plt.xticks(bins, env.attack_names, rotation=90)\n",
    "#     plt.xticks(np.arange(e), env.attack_names, rotation=90)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/Attacks_distribution.svg', format='svg', dpi=1000)\n",
    "\n",
    "\n",
    " # Plot attacks distribution alongside\n",
    "plt.figure(3,figsize=[10,10])\n",
    "plt.title(\"Attacks (mapped) distribution throughout  episodes\")\n",
    "for indx,e in enumerate([0,10,20,30,40,60,70,80,90]):\n",
    "    plt.subplot(3,3,indx+1)\n",
    "    plt.bar(range(5),attack_labels_list[e],tick_label =['Normal','Dos','Probe','R2L','U2R'])\n",
    "    plt.xlabel(\"{} epoch\".format(e))\n",
    "plt.tight_layout()\n",
    "plt.savefig('results/Attacks_mapped_distribution.svg', format='svg', dpi=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GdEEgnejoANJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MLhFt4v2oA5r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-3z12k-CoBqI"
   },
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k2EScB5ZoA8t"
   },
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "import itertools\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.metrics import  confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i1PgEGysoOlU"
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion Matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.3f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"Red\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5cSeFJb3oPVT"
   },
   "outputs": [],
   "source": [
    "formated_test_path = \"formated_test_adv.data\"\n",
    "\n",
    "with open(\"models/defender_agent_model.json\", \"r\") as jfile:\n",
    "    model = model_from_json(json.load(jfile))\n",
    "model.load_weights(\"models/defender_agent_model.h5\")\n",
    "\n",
    "model.compile(loss=huber_loss,optimizer=\"sgd\")\n",
    "\n",
    "\n",
    "# Define environment, game, make sure the batch_size is the same in train\n",
    "env_test = RLenv('test',formated_test_path = formated_test_path)\n",
    "\n",
    "\n",
    "total_reward = 0    \n",
    "\n",
    "\n",
    "true_labels = np.zeros(len(env_test.attack_types),dtype=int)\n",
    "estimated_labels = np.zeros(len(env_test.attack_types),dtype=int)\n",
    "estimated_correct_labels = np.zeros(len(env_test.attack_types),dtype=int)\n",
    "\n",
    "#states , labels = env.get_sequential_batch(test_path,batch_size = env.batch_size)\n",
    "states , labels = env_test.get_full()\n",
    "\n",
    "\n",
    "start_time=time.time()\n",
    "q = model.predict(states)\n",
    "actions = np.argmax(q,axis=1)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "8hFU1HF1oYFG",
    "outputId": "84467272-00c9-4381-a829-c58c1d86a5a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "Total reward: 14806 | Number of samples: 22544 | Accuracy = 65.68%\n",
      "       Estimated Correct Total   F1_score\n",
      "normal     11570    8595  9712  80.772484\n",
      "DoS         4171    3418  7458  58.784074\n",
      "Probe       3172    1491  2421  53.316646\n",
      "R2L         2900    1220  2753  43.162922\n",
      "U2R          731      82   200  17.615467\n"
     ]
    }
   ],
   "source": [
    "maped=[]\n",
    "for indx,label in labels.iterrows():\n",
    "    maped.append(env_test.attack_types.index(env_test.attack_map[label.idxmax()]))\n",
    "\n",
    "labels,counts = np.unique(maped,return_counts=True)\n",
    "true_labels[labels] += counts\n",
    "\n",
    "\n",
    "\n",
    "for indx,a in enumerate(actions):\n",
    "    estimated_labels[a] +=1              \n",
    "    if a == maped[indx]:\n",
    "        total_reward += 1\n",
    "        estimated_correct_labels[a] += 1\n",
    "\n",
    "\n",
    "action_dummies = pd.get_dummies(actions)\n",
    "posible_actions = np.arange(len(env_test.attack_types))\n",
    "for non_existing_action in posible_actions:\n",
    "    if non_existing_action not in action_dummies.columns:\n",
    "        action_dummies[non_existing_action] = np.uint8(0)\n",
    "labels_dummies = pd.get_dummies(maped)\n",
    "\n",
    "normal_f1_score = f1_score(labels_dummies[0].values,action_dummies[0].values)\n",
    "dos_f1_score = f1_score(labels_dummies[1].values,action_dummies[1].values)\n",
    "probe_f1_score = f1_score(labels_dummies[2].values,action_dummies[2].values)\n",
    "r2l_f1_score = f1_score(labels_dummies[3].values,action_dummies[3].values)\n",
    "u2r_f1_score = f1_score(labels_dummies[4].values,action_dummies[4].values)\n",
    "    \n",
    "\n",
    "Accuracy = [normal_f1_score,dos_f1_score,probe_f1_score,r2l_f1_score,u2r_f1_score]\n",
    "Mismatch = estimated_labels - true_labels\n",
    "\n",
    "acc = float(100*total_reward/len(states))\n",
    "print('\\r\\nTotal reward: {} | Number of samples: {} | Accuracy = {:.2f}%'.format(total_reward,\n",
    "      len(states),acc))\n",
    "outputs_df = pd.DataFrame(index = env_test.attack_types,columns = [\"Estimated\",\"Correct\",\"Total\",\"F1_score\"])\n",
    "for indx,att in enumerate(env_test.attack_types):\n",
    "   outputs_df.iloc[indx].Estimated = estimated_labels[indx]\n",
    "   outputs_df.iloc[indx].Correct = estimated_correct_labels[indx]\n",
    "   outputs_df.iloc[indx].Total = true_labels[indx]\n",
    "   outputs_df.iloc[indx].F1_score = Accuracy[indx]*100\n",
    "   outputs_df.iloc[indx].Mismatch = abs(Mismatch[indx])\n",
    "    \n",
    "    \n",
    "print(outputs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "colab_type": "code",
    "id": "HBxETWRcocbS",
    "outputId": "0e1e5a99-16ee-4316-b9f3-26cabd6f30e5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 6)\n",
    "width = 0.35\n",
    "pos = np.arange(len(true_labels))\n",
    "p1 = plt.bar(pos, estimated_correct_labels,width,color='y')\n",
    "p1 = plt.bar(pos+width,\n",
    "             (np.abs(estimated_correct_labels-true_labels)),width,\n",
    "             color='r')\n",
    "p2 = plt.bar(pos+width,np.abs(estimated_labels-estimated_correct_labels),width,\n",
    "             bottom=(np.abs(estimated_correct_labels-true_labels)),\n",
    "             color='g')\n",
    "\n",
    "ax.yaxis.set_tick_params(labelsize=15)\n",
    "ax.set_xticks(pos+width/2)\n",
    "ax.set_xticklabels(env.attack_types,rotation='vertical',fontsize = 'xx-large')\n",
    "\n",
    "#ax.set_yscale('log')\n",
    "\n",
    "#ax.set_ylim([0, 100])\n",
    "#ax.set_title('Test set scores',fontsize = 'xx-large')\n",
    "#ax.set_title('Test set scores, Acc = {:.2f}'.format(acc))\n",
    "plt.legend(('Correct estimated','False negative','False positive'),fontsize = 'x-large')\n",
    "plt.tight_layout()\n",
    "#plt.show()\n",
    "plt.savefig('results/test_adv_imp.svg', format='svg', dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "FBVTk9aujCuI",
    "outputId": "63d87333-7655-468a-aa89-b45fdd1e3957"
   },
   "outputs": [],
   "source": [
    "estimated_correct_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UphioXJOjSpn",
    "outputId": "70c9c724-c985-4815-9232-8078c1ac400a"
   },
   "outputs": [],
   "source": [
    "estimated_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "_XrjAwLzjbWf",
    "outputId": "fd943f8e-fa42-488f-8319-7eb6f2da087a"
   },
   "outputs": [],
   "source": [
    "true_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Jw9xTn9EkMku",
    "outputId": "388a29de-6718-4c6d-90f6-15874ab6df72"
   },
   "outputs": [],
   "source": [
    "np.abs(estimated_correct_labels-true_labels) # false negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OSneeTpxkYiU",
    "outputId": "40f73413-c3b6-4a8d-c103-eaa32d0f5e04"
   },
   "outputs": [],
   "source": [
    "np.abs(estimated_labels-estimated_correct_labels)  #false positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "id": "O0Z8IHZhonlP",
    "outputId": "b27f64cd-b3ec-4016-8907-8f6aed7ca7a8"
   },
   "outputs": [],
   "source": [
    "aggregated_data_test = np.array(maped)\n",
    "\n",
    "print('Performance measures on Test data')\n",
    "print('Accuracy =  {:.4f}'.format(accuracy_score( aggregated_data_test,actions)))\n",
    "print('F1 =  {:.4f}'.format(f1_score(aggregated_data_test,actions, average='weighted')))\n",
    "print('Precision_score =  {:.4f}'.format(precision_score(aggregated_data_test,actions, average='weighted')))\n",
    "print('recall_score =  {:.4f}'.format(recall_score(aggregated_data_test,actions, average='weighted')))\n",
    "\n",
    "cnf_matrix = confusion_matrix(aggregated_data_test,actions)\n",
    "np.set_printoptions(precision=2)\n",
    "plt.figure()\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix, classes=env.attack_types, normalize=True,\n",
    "                      title='Confusion Matrix')\n",
    "plt.savefig('results/confusion_matrix_adversarial.svg', format='svg', dpi=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 151
    },
    "colab_type": "code",
    "id": "60L3BNptopsZ",
    "outputId": "c9e531ee-a576-4d30-807f-4eddd1959f4e"
   },
   "outputs": [],
   "source": [
    "mapa = {0:'normal', 1:'DoS', 2:'Probe',3:'R2L',4:'U2R'}\n",
    "yt_app = pd.Series(maped).map(mapa)\n",
    "\n",
    "perf_per_class = pd.DataFrame(index=range(len(yt_app.unique())),columns=['name', 'acc','f1', 'pre','rec'])\n",
    "for i,x in enumerate(pd.Series(yt_app).value_counts().index):\n",
    "    y_test_hat_check = pd.Series(actions).map(mapa).copy()\n",
    "    y_test_hat_check[y_test_hat_check != x] = 'OTHER'\n",
    "    yt_app = pd.Series(maped).map(mapa).copy()\n",
    "    yt_app[yt_app != x] = 'OTHER'\n",
    "    ac=accuracy_score( yt_app,y_test_hat_check)\n",
    "    f1=f1_score( yt_app,y_test_hat_check,pos_label=x, average='binary')\n",
    "    pr=precision_score( yt_app,y_test_hat_check,pos_label=x, average='binary')\n",
    "    re=recall_score( yt_app,y_test_hat_check,pos_label=x, average='binary')\n",
    "    perf_per_class.iloc[i]=[x,ac,f1,pr,re]\n",
    "    \n",
    "print(\"\\r\\nOne vs All metrics: \\r\\n{}\".format(perf_per_class))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-i1UuwC8Zz_b"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "AE_RL_NSL-KDD.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
